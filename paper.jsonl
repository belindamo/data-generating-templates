{"id":"cookbook_2024","title":"Cookbook: A framework for improving LLM generative abilities via programmatic data generating templates","authors":"Avanika Narayan, Mayee F. Chen, Kush Bhatia, Christopher Ré","journal":"COLM","year":"2024","doi":"10.48550/arXiv.2410.05224","url":"https://arxiv.org/abs/2410.05224","keyAssumptions":"Training data must be semantically meaningful and generated by humans or LLMs","keyHypotheses":"Programmatic patterns over random tokens can improve LLM capabilities","strengths":"Novel paradigm, avoids privacy issues, up to 52.7% accuracy improvements","weaknesses":"Limited to pattern-based rules, unclear extension to complex reasoning","citation":"Narayan, A., Chen, M. F., Bhatia, K., & Ré, C. (2024). Cookbook: A framework for improving LLM generative abilities via programmatic data generating templates. COLM 2024.","notes":"Foundational work for template-based data generation","addedDate":"2025-08-26T19:40:00.000Z"}
{"id":"templatemath_2024","title":"Training and Evaluating Language Models with Template-based Data Generation","authors":"Yifan Zhang et al.","journal":"ArXiv","year":"2024","doi":"","url":"https://arxiv.org/abs/2411.18104","keyAssumptions":"Mathematical datasets must be manually created by experts","keyHypotheses":"LLMs can generate parameterized meta-templates for unlimited data synthesis","strengths":"7M+ problem dataset, addresses domain scarcity, code+natural language solutions","weaknesses":"Domain-specific to mathematics, GPT-4 dependency","citation":"Zhang, Y. et al. (2024). Training and Evaluating Language Models with Template-based Data Generation. ArXiv.","notes":"Template-based Data Generation (TDG) methodology","addedDate":"2025-08-26T19:40:00.000Z"}
{"id":"synalign_2025","title":"Few-shot LLM Synthetic Data with Distribution Matching","authors":"Jiyuan Ren et al.","journal":"WWW","year":"2025","doi":"","url":"https://arxiv.org/abs/2502.08661","keyAssumptions":"Synthetic data can be directly mixed with real data","keyHypotheses":"Distribution matching is crucial for effective synthetic data integration","strengths":"Addresses distribution mismatch, uncertainty tracking, online validation","weaknesses":"Complex distribution matching, may not generalize across data types","citation":"Ren, J. et al. (2025). Few-shot LLM Synthetic Data with Distribution Matching. WWW 2025.","notes":"SynAlign framework with MMD-based sampling","addedDate":"2025-08-26T19:40:00.000Z"}
{"id":"bare_2025","title":"BARE: Leveraging Base Language Models for Few-Shot Synthetic Data Generation","authors":"Alan Zhu et al.","journal":"ArXiv","year":"2025","doi":"","url":"https://arxiv.org/abs/2502.01697","keyAssumptions":"Instruction-tuned models are superior for synthetic data generation","keyHypotheses":"Base models offer superior diversity despite lower instruction-following","strengths":"Only 3 seed examples needed, 101% improvement on GSM8K, two-stage approach","weaknesses":"Two-stage complexity, refinement stage dependency","citation":"Zhu, A. et al. (2025). BARE: Leveraging Base Language Models for Few-Shot Synthetic Data Generation. ArXiv.","notes":"Base-Refine methodology for diversity enhancement","addedDate":"2025-08-26T19:40:00.000Z"}
{"id":"glan_2024","title":"Generalized Instruction Tuning for Language Models","authors":"Haoran Li et al.","journal":"ArXiv","year":"2024","doi":"","url":"https://arxiv.org/html/2402.13064v1","keyAssumptions":"Instruction datasets must be constructed from existing examples","keyHypotheses":"Knowledge taxonomy can generate comprehensive instruction data","strengths":"Eliminates seed requirement, comprehensive coverage, multi-domain excellence","weaknesses":"Extensive taxonomy development, domain-specific nuance gaps","citation":"Li, H. et al. (2024). Synthetic Data (Almost) from Scratch: Generalized Instruction Tuning for Language Models. ArXiv.","notes":"GLAN framework using human knowledge taxonomy","addedDate":"2025-08-26T19:40:00.000Z"}
{"id":"targen_2023","title":"TarGEN: Targeted Data Generation with Large Language Models","authors":"Himanshu Gupta et al.","journal":"ArXiv","year":"2023","doi":"","url":"https://arxiv.org/abs/2310.17876","keyAssumptions":"Synthetic data generation requires specific task instances as seeds","keyHypotheses":"Seedless multi-step prompting with self-correction enables quality generation","strengths":"Seedless generation, self-correction, 1-2% SuperGLUE improvements","weaknesses":"Self-correction limitations, limited diversity exploration","citation":"Gupta, H. et al. (2023). TarGEN: Targeted Data Generation with Large Language Models. ArXiv.","notes":"Multi-step prompting strategy for seedless generation","addedDate":"2025-08-26T19:40:00.000Z"}
{"id":"agentif_2025","title":"AGENTIF: Benchmarking Instruction Following of Large Language Models in Agentic Scenarios","authors":"Yunjia Qi et al.","journal":"ArXiv","year":"2025","doi":"","url":"https://arxiv.org/abs/2505.16944","keyAssumptions":"Standard instruction following evaluations are sufficient for agentic applications","keyHypotheses":"Agentic scenarios require specialized long and complex instruction evaluation","strengths":"First agentic benchmark, realistic scenarios, 1723 word avg instructions","weaknesses":"Evaluation-focused, reveals poor LLM performance","citation":"Qi, Y. et al. (2025). AGENTIF: Benchmarking Instruction Following of Large Language Models in Agentic Scenarios. ArXiv.","notes":"AgentIF benchmark for complex instruction evaluation","addedDate":"2025-08-26T19:40:00.000Z"}
{"id":"sifo_2024","title":"The SIFo Benchmark: Investigating the Sequential Instruction Following Ability of Large Language Models","authors":"Xinyi Chen et al.","journal":"EMNLP Findings","year":"2024","doi":"","url":"https://arxiv.org/abs/2406.19999","keyAssumptions":"Single instruction evaluation captures multi-instruction capabilities","keyHypotheses":"Sequential instruction following requires specialized evaluation methodology","strengths":"Addresses coherence and positional bias, objective verification","weaknesses":"Reveals fundamental robustness limitations across all models","citation":"Chen, X. et al. (2024). The SIFo Benchmark: Investigating the Sequential Instruction Following Ability of Large Language Models. EMNLP Findings.","notes":"Sequential instruction following (SIFo) evaluation framework","addedDate":"2025-08-26T19:40:00.000Z"}
{"id":"wildchat_2025","title":"WildChat-50m: A Deep Dive Into the Role of Synthetic Data in Post-Training","authors":"Benjamin Feuer et al.","journal":"ArXiv","year":"2025","doi":"","url":"https://arxiv.org/html/2501.18511v2","keyAssumptions":"Large-scale synthetic data quality comparison is intractable","keyHypotheses":"Massive multi-model datasets enable better synthetic data understanding","strengths":"Largest public chat dataset (50m), Re-Wild outperforms Tulu-3 with 40% samples","weaknesses":"Chat-focused, limited domain generalization","citation":"Feuer, B. et al. (2025). WildChat-50m: A Deep Dive Into the Role of Synthetic Data in Post-Training. ArXiv.","notes":"Comprehensive synthetic data generating model analysis","addedDate":"2025-08-26T19:40:00.000Z"}
{"id":"maxife_2025","title":"MaXIFE: Multilingual and Cross-lingual Instruction Following Evaluation","authors":"Yile Liu et al.","journal":"ACL","year":"2025","doi":"","url":"https://arxiv.org/abs/2506.01776","keyAssumptions":"English-centric evaluation adequately captures instruction following capabilities","keyHypotheses":"Multilingual instruction following presents unique evaluation challenges","strengths":"23 languages, 1667 tasks, dual evaluation methodology","weaknesses":"Evaluation-focused, doesn't address improvement methods","citation":"Liu, Y. et al. (2025). MaXIFE: Multilingual and Cross-lingual Instruction Following Evaluation. ACL 2025.","notes":"Comprehensive multilingual instruction following benchmark","addedDate":"2025-08-26T19:40:00.000Z"}
{"id":"synthllm_2025","title":"Scaling Laws of Synthetic Data for Language Models","authors":"Zeyu Qin et al.","journal":"ArXiv","year":"2025","doi":"","url":"https://arxiv.org/abs/2503.19551","keyAssumptions":"Raw web data is irreplaceable for pre-training","keyHypotheses":"Synthetic data can follow predictable scaling laws comparable to raw data","strengths":"Graph-based concept extraction, scaling law validation, 300B token plateau","weaknesses":"Complex graph algorithm requirements, model-specific scaling patterns","citation":"Qin, Z. et al. (2025). Scaling Laws of Synthetic Data for Language Models. ArXiv.","notes":"SynthLLM framework demonstrating synthetic data scalability","addedDate":"2025-08-26T19:40:00.000Z"}
{"id":"context_synthesis_2025","title":"Generalizing From Short to Long: Effective Data Synthesis for Long-Context Instruction Tuning","authors":"Wenhao Zhu et al.","journal":"ArXiv","year":"2025","doi":"","url":"https://arxiv.org/abs/2502.15592","keyAssumptions":"Long context training examples are necessary for long context capability","keyHypotheses":"Short context instruction tuning can generalize to longer contexts","strengths":"Context synthesis framework, outperforms prior synthesis approaches","weaknesses":"Limited to long-context scenarios, LLM dependency for context generation","citation":"Zhu, W. et al. (2025). Generalizing From Short to Long: Effective Data Synthesis for Long-Context Instruction Tuning. ArXiv.","notes":"Context synthesis for long-context instruction tuning","addedDate":"2025-08-26T19:40:00.000Z"}
{"id":"synthetic_survey_2025","title":"Synthetic Data Generation Using Large Language Models: Advances in Text and Code","authors":"Mihai Nadas, Laura Diosan, Andreea Tomescu","journal":"IEEE Access","year":"2025","doi":"10.1109/ACCESS.2025.3589503","url":"https://arxiv.org/abs/2503.14023","keyAssumptions":"Comprehensive survey coverage of synthetic data generation is needed","keyHypotheses":"LLMs are transforming synthetic data generation across domains","strengths":"Comprehensive survey, covers text and code domains, mitigation strategies","weaknesses":"Survey paper, limited novel methodological contributions","citation":"Nadas, M., Diosan, L., & Tomescu, A. (2025). Synthetic Data Generation Using Large Language Models: Advances in Text and Code. IEEE Access.","notes":"Comprehensive survey of LLM-based synthetic data generation","addedDate":"2025-08-26T19:40:00.000Z"}
{"id":"data_augmentation_survey_2025","title":"Text Data Augmentation for Large Language Models: A Comprehensive Survey of Methods, Challenges, and Opportunities","authors":"Yaping Chai, Haoran Xie, Joe S. Qin","journal":"ArXiv","year":"2025","doi":"","url":"https://arxiv.org/abs/2501.18845","keyAssumptions":"Comprehensive data augmentation taxonomy is needed for LLMs","keyHypotheses":"LLMs enable sophisticated data augmentation through various approaches","strengths":"Comprehensive classification, covers simple to hybrid augmentation","weaknesses":"Survey paper, limited experimental validation","citation":"Chai, Y., Xie, H., & Qin, J. S. (2025). Text Data Augmentation for Large Language Models: A Comprehensive Survey of Methods, Challenges, and Opportunities. ArXiv.","notes":"Taxonomy of data augmentation methods for LLMs","addedDate":"2025-08-26T19:40:00.000Z"}
{"id":"learning_failures_2025","title":"Learning from Reasoning Failures via Synthetic Data Generation","authors":"Gabriela Ben Melech Stan et al.","journal":"ArXiv","year":"2025","doi":"","url":"https://arxiv.org/abs/2504.14523","keyAssumptions":"Synthetic data generation should not target specific model weaknesses","keyHypotheses":"Failure-targeted synthetic data generation can improve reasoning capabilities","strengths":"Error analysis-driven generation, 553k example dataset, exceeds real data performance","weaknesses":"Requires frontier model analysis, specific to multimodal reasoning failures","citation":"Stan, G. B. M. et al. (2025). Learning from Reasoning Failures via Synthetic Data Generation. ArXiv.","notes":"Failure-targeted synthetic data generation for multimodal models","addedDate":"2025-08-26T19:40:00.000Z"}